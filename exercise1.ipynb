{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f90582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885a4f6",
   "metadata": {},
   "source": [
    "\n",
    "Now that you have the sample_hours and sample_weekends tensors prepared, you'll use them to build the rush_hour_feature function.\n",
    "\n",
    "Exercise 1 - rush_hour_feature\n",
    "\n",
    "Implement the rush_hour_feature function.\n",
    "\n",
    "Your Task:\n",
    "\n",
    "Define the individual conditions:\n",
    "Define is_morning_rush to be True where the hours_tensor is greater than or equal to 8.0 AND less than 10.0.\n",
    "Define is_evening_rush to be True where the hours_tensor is greater than or equal to 16.0 AND less than 19.0.\n",
    "Define is_weekday to be True where the weekends_tensor is equal to 0.\n",
    "Combine the conditions:\n",
    "Define is_rush_hour_mask by combining the three boolean tensors. The logic should be True only if it's a weekday AND it's either morning rush OR evening rush.\n",
    "Hint: You can use standard comparison operators (>=, <, ==) and logical operators like & (AND) and | (OR) directly on PyTorch tensors.\n",
    "\n",
    "Additional Code Hints (Click to expand if you are stuck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea0dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 5 rows of data as a single 2D tensor\n",
    "sample_tensor = torch.tensor([\n",
    "    # distance, time_of_day, is_weekend, delivery_time\n",
    "    [1.60,      8.20,        0,          7.22],   # row 1\n",
    "    [13.09,     16.80,       1,          32.41],  # row 2       \n",
    "    [6.97,      8.02,        1,          17.47],  # row 3\n",
    "    [10.66,     16.07,       0,          37.17],  # row 4\n",
    "    [18.24,     13.47,       0,          38.36]   # row 5\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8fabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sliced Tensors ---\n",
      "Sample Hours:    tensor([ 8.2000, 16.8000,  8.0200, 16.0700, 13.4700])\n",
      "Sample Weekends: tensor([0., 1., 1., 0., 0.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tensor slicing to separate out each column\n",
    "# Slicing syntax is [:, column_index]\n",
    "sample_hours = sample_tensor[:, 1]\n",
    "sample_weekends = sample_tensor[:, 2]\n",
    "\n",
    "print(\"--- Sliced Tensors ---\")\n",
    "print(f\"Sample Hours:    {sample_hours}\")\n",
    "print(f\"Sample Weekends: {sample_weekends}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af624ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_input = {'distance_miles': {0: 1.6,\n",
    "  1: 13.09,\n",
    "  2: 6.97,\n",
    "  3: 10.66,\n",
    "  4: 18.24,\n",
    "  5: 5.74,\n",
    "  6: 8.8,\n",
    "  7: 15.36,\n",
    "  8: 5.35,\n",
    "  9: 2.46},\n",
    " 'time_of_day_hours': {0: 8.2,\n",
    "  1: 16.8,\n",
    "  2: 8.02,\n",
    "  3: 16.07,\n",
    "  4: 13.47,\n",
    "  5: 16.59,\n",
    "  6: 12.25,\n",
    "  7: 11.76,\n",
    "  8: 9.42,\n",
    "  9: 14.44},\n",
    " 'is_weekend': {0: 0, 1: 1, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0},\n",
    " 'delivery_time_minutes': {0: 7.22,\n",
    "  1: 32.41,\n",
    "  2: 17.47,\n",
    "  3: 37.17,\n",
    "  4: 38.36,\n",
    "  5: 29.06,\n",
    "  6: 23.94,\n",
    "  7: 32.4,\n",
    "  8: 17.06,\n",
    "  9: 14.09}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da9c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "file_path = './data_with_features.csv'\n",
    "# data_df = pd.read_csv(file_path)\n",
    "data_df = pd.DataFrame(dict_input)\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"Dataset Shape: {data_df.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5c1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: rush_hour_feature\n",
    "\n",
    "def rush_hour_feature(hours_tensor, weekends_tensor):\n",
    "    \"\"\"\n",
    "    Engineers a new binary feature indicating if a delivery is in a weekday rush hour.\n",
    "\n",
    "    Args:\n",
    "        hours_tensor (torch.Tensor): A tensor of delivery times of day.\n",
    "        weekends_tensor (torch.Tensor): A tensor indicating if a delivery is on a weekend.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of 0s and 1s indicating weekday rush hour.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Define rush hour and weekday conditions\n",
    "    is_morning_rush = is_morning_rush = (hours_tensor >= 8) & (hours_tensor <= 10)\n",
    "    is_evening_rush = is_evening_rush = (hours_tensor >= 16) & (hours_tensor <= 19)\n",
    "    is_weekday = weekends_tensor ==0 \n",
    "\n",
    "    # Combine the conditions to create the final rush hour mask\n",
    "    is_rush_hour_mask = (is_morning_rush | is_evening_rush ) & is_weekday\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Convert the boolean mask to a float tensor to use as a numerical feature\n",
    "    return is_rush_hour_mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7642bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Hours:     [ 8.2  16.8   8.02 16.07 13.47]\n",
      "Sample Weekends:  [0. 1. 1. 0. 0.]\n",
      "Is Rush Hour?:    [1. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "rush_hour_for_sample = rush_hour_feature(sample_hours, sample_weekends)\n",
    "\n",
    "print(f\"Sample Hours:     {sample_hours.numpy()}\")\n",
    "print(f\"Sample Weekends:  {sample_weekends.numpy()}\")\n",
    "print(f\"Is Rush Hour?:    {rush_hour_for_sample.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35e89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Converts a pandas DataFrame into prepared PyTorch tensors for modeling.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the raw delivery data.\n",
    "\n",
    "    Returns:\n",
    "        prepared_features (torch.Tensor): The final 2D feature tensor for the model.\n",
    "        prepared_targets (torch.Tensor): The final 2D target tensor.\n",
    "        results_dict (dict): A dictionary of intermediate tensors for testing purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the data from the DataFrame as a NumPy array\n",
    "    # (There's no direct torch.from_dataframe(), so we use .values to get a NumPy array first)\n",
    "    all_values = df.values\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Convert all the values from the DataFrame into a single PyTorch tensor\n",
    "    full_tensor = torch.tensor(all_values, dtype = torch.float32)\n",
    "\n",
    "    # Use tensor slicing to separate out each raw column\n",
    "    raw_distances = full_tensor[:,0]\n",
    "    raw_hours = full_tensor[:,1]\n",
    "    raw_weekends = full_tensor[:,2]\n",
    "    raw_targets = full_tensor[:,3]\n",
    "\n",
    "    # Call your rush_hour_feature() function to engineer the new feature\n",
    "    is_rush_hour_feature = rush_hour_feature(raw_hours,raw_weekends )\n",
    "\n",
    "    # Use the .unsqueeze(1) method to reshape the four 1D feature tensors into 2D column vectors\n",
    "    distances_col = raw_distances.unsqueeze(1)\n",
    "    hours_col = raw_hours.unsqueeze(1)\n",
    "    weekends_col = raw_weekends.unsqueeze(1)\n",
    "    rush_hour_col = is_rush_hour_feature.unsqueeze(1)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Normalize the continuous feature columns (distance and time)\n",
    "    dist_mean, dist_std = distances_col.mean(), distances_col.std()\n",
    "    hours_mean, hours_std = hours_col.mean(), hours_col.std()\n",
    " \n",
    "    distances_norm = (distances_col - dist_mean) / dist_std\n",
    "    hours_norm = (hours_col - hours_mean) / hours_std\n",
    "\n",
    "    # Combine all prepared 2D features into a single tensor\n",
    "    prepared_features = torch.cat([\n",
    "        distances_norm,\n",
    "        hours_norm,\n",
    "        weekends_col,\n",
    "        rush_hour_col\n",
    "    ], dim=1) # dim=1 concatenates them column-wise, stacking features side by side\n",
    "\n",
    "    # Prepare targets by ensuring they are the correct shape\n",
    "    prepared_targets = raw_targets.unsqueeze(1)\n",
    "    \n",
    "    # Dictionary for Testing Purposes\n",
    "    results_dict = {\n",
    "        'full_tensor': full_tensor,\n",
    "        'raw_distances': raw_distances,\n",
    "        'raw_hours': raw_hours,\n",
    "        'raw_weekends': raw_weekends,\n",
    "        'raw_targets': raw_targets,\n",
    "        'distances_col': distances_col,\n",
    "        'hours_col': hours_col,\n",
    "        'weekends_col': weekends_col,\n",
    "        'rush_hour_col': rush_hour_col\n",
    "    }\n",
    "    \n",
    "\n",
    "    return prepared_features, prepared_targets, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6036bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Tensor (Before Preparation) ---\n",
      "\n",
      "Shape: torch.Size([5, 4])\n",
      "Values:\n",
      " tensor([[ 1.6000,  8.2000,  0.0000,  7.2200],\n",
      "        [13.0900, 16.8000,  1.0000, 32.4100],\n",
      "        [ 6.9700,  8.0200,  1.0000, 17.4700],\n",
      "        [10.6600, 16.0700,  0.0000, 37.1700],\n",
      "        [18.2400, 13.4700,  0.0000, 38.3600]])\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Prepared Tensors (After Preparation) ---\n",
      "\n",
      "--- Prepared Features ---\n",
      "\n",
      "Shape: torch.Size([5, 4])\n",
      "Values:\n",
      " tensor([[-1.3562, -1.0254,  0.0000,  1.0000],\n",
      "        [ 0.4745,  1.0197,  1.0000,  0.0000],\n",
      "        [-0.5006, -1.0682,  1.0000,  0.0000],\n",
      "        [ 0.0873,  0.8461,  0.0000,  1.0000],\n",
      "        [ 1.2951,  0.2278,  0.0000,  0.0000]])\n",
      "\n",
      "--- Prepared Targets ---\n",
      "Shape: torch.Size([5, 1])\n",
      "Values:\n",
      " tensor([[ 7.2200],\n",
      "        [32.4100],\n",
      "        [17.4700],\n",
      "        [37.1700],\n",
      "        [38.3600]])\n"
     ]
    }
   ],
   "source": [
    "# Create a small test DataFrame with the first 5 entries\n",
    "test_df = data_df.head(5).copy()\n",
    "\n",
    "# Print the \"Before\" state as a raw tensor\n",
    "raw_test_tensor = torch.tensor(test_df.values, dtype=torch.float32)\n",
    "print(\"--- Raw Tensor (Before Preparation) ---\\n\")\n",
    "print(f\"Shape: {raw_test_tensor.shape}\")\n",
    "print(\"Values:\\n\", raw_test_tensor)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Run the function to get the prepared \"after\" tensors\n",
    "test_features, test_targets, _ = prepare_data(test_df)\n",
    "\n",
    "# Print the \"After\" state\n",
    "print(\"--- Prepared Tensors (After Preparation) ---\")\n",
    "print(\"\\n--- Prepared Features ---\\n\")\n",
    "print(f\"Shape: {test_features.shape}\")\n",
    "print(\"Values:\\n\", test_features)\n",
    "\n",
    "print(\"\\n--- Prepared Targets ---\")\n",
    "print(f\"Shape: {test_targets.shape}\")\n",
    "print(\"Values:\\n\", test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f5615cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the entire DataFrame to get the final feature and target tensors.\n",
    "features, targets, _ = prepare_data(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83fdc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    Initializes the neural network model, optimizer, and loss function.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Sequential): The initialized PyTorch sequential model.\n",
    "        optimizer (torch.optim.Optimizer): The initialized optimizer for training.\n",
    "        loss_function: The initialized loss function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the random seed for reproducibility of results (DON'T MANIPULATE IT)\n",
    "    torch.manual_seed(41)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the model architecture using nn.Sequential\n",
    "    model = nn.Sequential(\n",
    "        # Input layer (Linear): 4 input features, 64 output features\n",
    "        nn.Linear(4,64),\n",
    "        # First ReLU activation function\n",
    "        nn.ReLU(),\n",
    "        # Hidden layer (Linear): 64 inputs, 32 outputs\n",
    "        nn.Linear(64,32),\n",
    "        # Second ReLU activation function\n",
    "        nn.ReLU(),\n",
    "        # Output layer (Linear): 32 inputs, 1 output (the prediction)\n",
    "        nn.Linear(32,1)\n",
    "    ) \n",
    "    \n",
    "    # Define the optimizer (Stochastic Gradient Descent)\n",
    "    optimizer = optim.SGD(model.parameters(), lr =0.01)\n",
    "\n",
    "    # Define the loss function (Mean Squared Error for regression)\n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return model, optimizer, loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb9675dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features, targets, epochs, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains the model using the provided data for a number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        features (torch.Tensor): The input features for training.\n",
    "        targets (torch.Tensor): The target values for training.\n",
    "        epochs (int): The number of training epochs.\n",
    "        verbose (bool): If True, prints training progress. Defaults to True.\n",
    "        \n",
    "    Returns:\n",
    "        model (nn.Sequential): The trained model.\n",
    "        losses (list): A list of loss values recorded every 5000 epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize a list to store the loss\n",
    "    losses = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Initialize the model, optimizer, and loss function using `init_model`\n",
    "    model, optimizer, loss_function = init_model()\n",
    "\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Forward pass: Make predictions\n",
    "        outputs = model(features)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_function (outputs,targets )\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model's parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    ### END CODE HERE ### \n",
    "\n",
    "        # Every 5000 epochs, record the loss and print the progress\n",
    "        if (epoch + 1) % 5000 == 0:\n",
    "            losses.append(loss.item())\n",
    "            if verbose:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb431510",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model, loss = train_model(features, targets, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b0e6f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5000/30000], Loss: 0.0000\n",
      "Epoch [10000/30000], Loss: 0.0000\n",
      "Epoch [15000/30000], Loss: 0.0000\n",
      "Epoch [20000/30000], Loss: 0.0000\n",
      "Epoch [25000/30000], Loss: 0.0000\n",
      "Epoch [30000/30000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model, loss = train_model(features, targets, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69e7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable gradient calculation for efficient predictions\n",
    "with torch.no_grad():\n",
    "    # Perform a forward pass to get model predictions\n",
    "    predicted_outputs = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6b1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
